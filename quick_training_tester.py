# ramp_cnn_2h_tester.py (æœ€ç»ˆä¿®å¤ç‰ˆ V6.0 - å¼•å…¥ Peak æå–)

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim import Adam
from torch.optim.lr_scheduler import CyclicLR
import numpy as np
import os
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Any
from tqdm import tqdm
import sys
import logging

# ç¡®ä¿ data_processor.py å­˜åœ¨ä¸”å·²ä¿®æ­£è§’åº¦å½’ä¸€åŒ–
try:
    from data_processor import RadarDataset, RadarDataProcessor, radar_configs, label_map
except ImportError:
    print("FATAL ERROR: æ— æ³•å¯¼å…¥ data_processor.pyã€‚è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«å¿…è¦çš„ç±»å’Œå˜é‡ã€‚")
    sys.exit(1)

logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(message)s')


# ==============================================================================
# ä¼˜åŒ–åçš„æ¨¡å‹å®šä¹‰ (Lite Version) - ä¿æŒä¸å˜
# ==============================================================================

class Conv3DAutoencoderLite(nn.Module):
    def __init__(self, in_channels: int, output_channels: int = 192):
        super().__init__()
        self.output_channels = output_channels
        self.encoder = nn.Sequential(
            nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),
            nn.BatchNorm3d(32),
            nn.ReLU(inplace=True),
            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1)),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.Conv3d(64, output_channels, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1)),
            nn.BatchNorm3d(output_channels),
            nn.ReLU(inplace=True),
        )
        # Decoder éƒ¨åˆ†çœç•¥ï¼Œå› ä¸ºæ¨¡å‹åªè¿”å› features
        self.decoder = nn.Sequential(
            nn.ConvTranspose3d(output_channels, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2),
                               padding=(1, 1, 1), output_padding=(0, 1, 1)),
            nn.BatchNorm3d(64),
            nn.PReLU(),
            nn.ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 2, 2),
                               padding=(1, 1, 1), output_padding=(0, 1, 1)),
            nn.BatchNorm3d(32),
            nn.PReLU(),
            nn.ConvTranspose3d(32, in_channels, kernel_size=(3, 3, 3), padding=(1, 1, 1)),
        )

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        features = self.encoder(x)
        reconstructed = self.decoder(features)
        return features, reconstructed


class FeatureFusionModuleLite(nn.Module):
    def __init__(self, ra_channels: int, rv_channels: int, va_channels: int, output_channels: int):
        super().__init__()
        self.rv_to_ra = nn.Sequential(
            nn.Conv3d(rv_channels, ra_channels, kernel_size=1),
            nn.BatchNorm3d(ra_channels),
            nn.ReLU(inplace=True)
        )
        self.va_to_ra = nn.Sequential(
            nn.Conv3d(va_channels, ra_channels, kernel_size=1),
            nn.BatchNorm3d(ra_channels),
            nn.ReLU(inplace=True)
        )
        self.fusion_conv = nn.Sequential(
            nn.Conv3d(ra_channels * 3, output_channels, kernel_size=3, padding=1),
            nn.BatchNorm3d(output_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, ra_features: torch.Tensor, rv_features: torch.Tensor, va_features: torch.Tensor) -> torch.Tensor:
        rv_proj = self.rv_to_ra(rv_features)
        va_proj = self.va_to_ra(va_features)
        target_size = ra_features.shape[2:]
        rv_aligned = F.interpolate(rv_proj, size=target_size, mode='trilinear', align_corners=False)
        va_aligned = F.interpolate(va_proj, size=target_size, mode='trilinear', align_corners=False)
        fused = torch.cat([ra_features, rv_aligned, va_aligned], dim=1)
        fused = self.fusion_conv(fused)
        return fused


class RAMP_CNN_Lite(nn.Module):
    def __init__(self, num_classes: int = 6, sequence_length: int = 4):
        super().__init__()
        AE_OUT_CH = 192
        FUSION_OUT_CH = 384

        self.ra_ae = Conv3DAutoencoderLite(in_channels=2, output_channels=AE_OUT_CH)
        self.rv_ae = Conv3DAutoencoderLite(in_channels=1, output_channels=AE_OUT_CH)
        self.va_ae = Conv3DAutoencoderLite(in_channels=1, output_channels=AE_OUT_CH)

        self.fusion = FeatureFusionModuleLite(AE_OUT_CH, AE_OUT_CH, AE_OUT_CH, FUSION_OUT_CH)

        self.output_conv = nn.Sequential(
            nn.Conv3d(FUSION_OUT_CH, 128, kernel_size=3, padding=1),
            nn.BatchNorm3d(128),
            nn.ReLU(inplace=True),
            nn.Upsample(size=(sequence_length, 128, 128), mode='trilinear', align_corners=False),
            nn.Conv3d(128, 64, kernel_size=3, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.Conv3d(64, num_classes, kernel_size=1)
        )
        self.sequence_length = sequence_length

        # Focal Loss åç½®åˆå§‹åŒ–
        p = 0.01
        bias_init = -np.log((1 - p) / p)

        last_conv = self.output_conv[-1]
        if isinstance(last_conv, nn.Conv3d):
            last_conv.bias.data.fill_(bias_init)
        else:
            logging.warning("Warning: Could not find final Conv3d layer for bias initialization.")

    def forward(self, ra_input: torch.Tensor, rv_input: torch.Tensor, va_input: torch.Tensor) -> torch.Tensor:
        ra_features, _ = self.ra_ae(ra_input)
        rv_input_3d = rv_input.unsqueeze(1)
        rv_features, _ = self.rv_ae(rv_input_3d)
        va_input_3d = va_input.unsqueeze(1)
        va_features, _ = self.va_ae(va_input_3d)
        fused_features = self.fusion(ra_features, rv_features, va_features)
        output = self.output_conv(fused_features)
        return output


# ==============================================================================
# MetricCalculator ç±» (å…³é”®ä¿®æ”¹ï¼šå¼•å…¥ Peak æå–/NMS)
# ==============================================================================

class MetricCalculator:
    def __init__(self, processor: RadarDataProcessor, score_thresh: float = 0.2,
                 pixel_range_thresh: float = 3.0, pixel_angle_thresh: float = 3.0):
        self.processor = processor
        self.class_indices = list(label_map.keys())

        # ä¿æŒæä½é˜ˆå€¼ï¼Œä½† Peak æå–ä¼šå¤§å¹…å‡å°‘å®é™…é¢„æµ‹æ•°
        self.score_threshold = score_thresh
        self.PIXEL_RANGE_THRESHOLD = pixel_range_thresh
        self.PIXEL_ANGLE_THRESHOLD = pixel_angle_thresh

    def _extract_peaks(self, heatmap_logits: np.ndarray) -> List[Dict]:
        """ä½¿ç”¨ Max Pooling æå– CenterNet é£æ ¼çš„ Peak (æ›¿ä»£ NMS)"""
        # (C, 1, H, W) -> (C, H, W)
        heatmap = 1.0 / (1.0 + np.exp(-heatmap_logits))
        heatmap_2d = heatmap[:, 0, :, :]

        C, H, W = heatmap_2d.shape

        # 1. å¯»æ‰¾å±€éƒ¨æœ€å¤§å€¼ (ä½¿ç”¨ Max Pooling æ¨¡æ‹Ÿ NMS)
        # å°† numpy æ•°ç»„è½¬æ¢ä¸º torch Tensor
        scores_tensor = torch.from_numpy(heatmap_2d).unsqueeze(0)  # (1, C, H, W)

        # 3x3 Max Poolingï¼Œæ­¥é•¿ 1ï¼Œå¡«å…… 1
        # è¿™å°†æ‰¾åˆ°æ¯ä¸ª 3x3 åŒºåŸŸå†…çš„æœ€å¤§å€¼
        max_pooled = F.max_pool2d(scores_tensor, kernel_size=3, stride=1, padding=1)

        # 2. åªæœ‰å½“åˆ†æ•° = å±€éƒ¨æœ€å¤§å€¼æ—¶ï¼Œæ‰è®¤ä¸ºå®ƒæ˜¯ Peak
        # æ­¤å¤–ï¼Œåˆ†æ•°å¿…é¡»é«˜äº SCORE_THRESHOLD
        is_peak = (scores_tensor == max_pooled)
        is_above_thresh = (scores_tensor >= self.score_threshold)

        # ç»“åˆæ¡ä»¶ï¼šæ˜¯ Peak ä¸”é«˜äºé˜ˆå€¼
        peaks_mask = (is_peak & is_above_thresh).squeeze(0).numpy()  # (C, H, W)

        predictions = []

        for c in range(C):
            class_id = self.class_indices[c]

            # æ‰¾åˆ° Peak çš„åæ ‡
            y_indices, x_indices = np.where(peaks_mask[c])

            scores_c = heatmap_2d[c]

            for y, x in zip(y_indices, x_indices):
                predictions.append({
                    'class_id': class_id,
                    'score': scores_c[y, x],
                    'y': y,  # åƒç´  y åæ ‡ (Range/H)
                    'x': x,  # åƒç´  x åæ ‡ (Angle/W)
                })

        return predictions

    def _match_objects(self, preds: List[Dict], gts: List[Dict]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        if not gts or not preds:
            return np.array([]), np.array([]), np.array([])

        pred_scores = np.array([p['score'] for p in preds])
        pred_tps = np.zeros(len(preds), dtype=bool)
        gt_matched = np.zeros(len(gts), dtype=bool)

        gt_coords = np.array([[g['y'], g['x'], g['class_id']] for g in gts])
        sort_indices = np.argsort(pred_scores)[::-1]

        for p_idx in sort_indices:
            p = preds[p_idx]
            p_y, p_x, p_class = p['y'], p['x'], p['class_id']
            best_match_idx = -1

            for g_idx, g_coord in enumerate(gt_coords):
                g_y, g_x, g_class = g_coord[0], g_coord[1], g_coord[2]

                if gt_matched[g_idx] or g_class != p_class:
                    continue

                # åŒ¹é…é€»è¾‘ï¼šY->Y, X->X åƒç´ åŒ¹é…
                y_diff = abs(p_y - g_y)
                x_diff = abs(p_x - g_x)

                if y_diff < self.PIXEL_RANGE_THRESHOLD and x_diff < self.PIXEL_ANGLE_THRESHOLD:
                    best_match_idx = g_idx
                    break

            if best_match_idx != -1:
                pred_tps[p_idx] = True
                gt_matched[best_match_idx] = True

        return pred_tps, pred_scores, np.array([p['class_id'] for p in preds])

    # calculate_ap_ar ä¿æŒä¸å˜
    def calculate_ap_ar(self, all_preds: List[Tuple], all_gts: List[Dict]) -> Dict:
        all_tp = []
        all_scores = []
        num_gt = len(all_gts)

        for preds, gts in all_preds:
            tps, scores, _ = self._match_objects(preds, gts)
            all_tp.append(tps)
            all_scores.append(scores)

        if all_tp:
            all_tp = np.concatenate(all_tp).astype(bool)
        else:
            all_tp = np.array([], dtype=bool)
        all_scores = np.concatenate(all_scores) if all_scores else np.array([])

        if len(all_scores) == 0 or num_gt == 0:
            return {'AP': 0.0, 'AR': 0.0, 'num_gt': num_gt}

        sort_indices = np.argsort(all_scores)[::-1]
        all_tp = all_tp[sort_indices]

        tp_cumsum = np.cumsum(all_tp).astype(float)
        fp_cumsum = np.cumsum(~all_tp).astype(float)

        precision = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
        recall = tp_cumsum / (num_gt + 1e-6)

        recall = np.concatenate(([0.], recall))
        precision = np.concatenate(([1.], precision))
        for i in range(len(precision) - 1, 0, -1):
            precision[i - 1] = np.maximum(precision[i - 1], precision[i])

        i = np.where(recall[1:] != recall[:-1])[0]
        ap = np.sum((recall[i + 1] - recall[i]) * precision[i + 1])
        ar = recall[-1] if num_gt > 0 else 0.0

        return {'AP': ap * 100, 'AR': ar * 100, 'num_gt': num_gt}


# ==============================================================================
# RAMP_CNNTrainer ç±» - ä¿æŒä¸å˜
# ==============================================================================

class RAMP_CNNTrainer:
    def __init__(self, model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, device: torch.device,
                 metric_calculator: MetricCalculator):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.metric_calculator = metric_calculator
        self.optimizer = None
        self.scheduler = None

        self.criterion = self.centernet_focal_loss

    def centernet_focal_loss(self, pred_logits: torch.Tensor, target: torch.Tensor, alpha: float = 4,
                             gamma: float = 2) -> torch.Tensor:
        # ç»´åº¦è½¬æ¢ (B, C, T, H, W) -> (B, T, H, W, C)
        pred_logits = pred_logits.permute(0, 2, 3, 4, 1).contiguous()
        target = target.permute(0, 2, 3, 4, 1).contiguous()
        pred_prob = torch.sigmoid(pred_logits)

        pos_weight = target * torch.pow(target, alpha)
        neg_weight = (1. - target) * torch.pow(1. - target, alpha)

        pos_loss = -torch.log(pred_prob.clamp(min=1e-4)) * torch.pow(1. - pred_prob, gamma)
        neg_loss = -torch.log(1. - pred_prob.clamp(max=1.0 - 1e-4)) * torch.pow(pred_prob, gamma)

        loss = pos_weight * pos_loss + neg_weight * neg_loss

        num_targets = torch.sum(target.gt(0.99).float())
        loss = torch.sum(loss) / torch.clamp(num_targets, min=1.0)

        return loss

    def train_epoch(self, epoch: int) -> float:
        self.model.train()
        total_loss = 0
        num_batches = 0
        data_iterator = tqdm(self.train_loader, desc=f'Epoch {epoch} (Train)', leave=False)

        for _, batch in enumerate(data_iterator):
            ra_input = batch['ra'].to(self.device)
            rv_input = batch['rv'].to(self.device)
            va_input = batch['va'].to(self.device)

            target = batch['gt'].to(self.device)
            target = target.squeeze()
            target = target.permute(0, 4, 1, 2, 3).contiguous()  # (B, C, T, H, W)

            self.optimizer.zero_grad()
            output = self.model(ra_input, rv_input, va_input)

            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            self.scheduler.step()

            total_loss += loss.item()
            num_batches += 1
            data_iterator.set_postfix(loss=loss.item())

        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        return avg_loss

    def evaluate(self, loader: DataLoader) -> Dict[str, float]:
        if loader is None:
            return {'AP': 0.0, 'AR': 0.0, 'num_gt': 0}

        self.model.eval()
        all_predictions_and_gts = []
        all_gt_centers = []

        with torch.no_grad():
            for batch in tqdm(loader, desc="Evaluating", leave=False):
                ra_input = batch['ra'].to(self.device)
                rv_input = batch['rv'].to(self.device)
                va_input = batch['va'].to(self.device)
                gt_target = batch['gt']

                output_logits = self.model(ra_input, rv_input, va_input)

                if torch.isnan(output_logits).any() or torch.isinf(output_logits).any():
                    logging.error("FATAL: Model output contains NaN/Inf values! Training failed.")
                    return {'AP': 0.0, 'AR': 0.0, 'num_gt': 0}

                gt_target = gt_target.squeeze().cpu().numpy()  # (B, T, H, W, C)
                pred_np = output_logits.cpu().numpy()  # (B, C, T, H, W)

                pred_np_last_frame = pred_np[:, :, -1:, :, :]  # (B, C, 1, H, W)
                gt_np_last_frame = gt_target[:, -1:, :, :, :]  # (B, 1, H, W, C)

                B, C_pred, D_pred, H, W = pred_np_last_frame.shape

                for b in range(B):
                    gt_frame_squeezed = gt_np_last_frame[b, 0, :, :, :]  # (H, W, C)

                    # æå– GT ç›®æ ‡ä¸­å¿ƒ (åƒç´  y, x)
                    gt_y, gt_x, gt_c = np.where(gt_frame_squeezed > 0.99)

                    current_gts = []
                    for y, x, c_idx in zip(gt_y, gt_x, gt_c):
                        current_gts.append({
                            'class_id': self.metric_calculator.class_indices[c_idx],
                            'y': y,
                            'x': x,
                        })

                    pred_frame_logits = pred_np_last_frame[b, :, 0:1, :, :]
                    current_preds = self.metric_calculator._extract_peaks(
                        pred_frame_logits
                    )

                    # æ‰“å° Logits çš„ min/maxï¼Œç”¨äºè¯Šæ–­
                    if b == 0:
                        pred_min = pred_frame_logits.min()
                        pred_max = pred_frame_logits.max()
                        logging.info(f"Batch {b} Max Pred Logit: {pred_max:.4f}, Min Pred Logit: {pred_min:.4f}")
                        logging.info(f"Total predictions found: {len(current_preds)}")

                    all_predictions_and_gts.append((current_preds, current_gts))
                    all_gt_centers.extend(current_gts)

        results = self.metric_calculator.calculate_ap_ar(all_predictions_and_gts, all_gt_centers)
        return results


def plot_metrics(history: Dict[str, List[float]], total_epochs: int):
    # æ­¤æ–¹æ³•ä¿æŒä¸å˜
    epochs = range(1, total_epochs + 1)
    fig, ax1 = plt.subplots(figsize=(10, 5))
    color = 'tab:red'
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss (Focal)', color=color)
    ax1.plot(epochs, history['train_loss'], label='Training Loss', color=color)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.grid(True, linestyle='--')
    if 'AP' in history and 'AR' in history:
        ax2 = ax1.twinx()
        color = 'tab:blue'
        ax2.set_ylabel('Performance (%)', color=color)
        ax2.plot(epochs, history['AP'], label='Average Precision (AP)', color='tab:blue', marker='o')
        ax2.plot(epochs, history['AR'], label='Average Recall (AR)', color='tab:green', marker='x')
        ax2.tick_params(axis='y', labelcolor=color)
        ax2.set_ylim(0, 100)
        lines, labels = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax2.legend(lines + lines2, labels + labels2, loc='lower left')
    plt.title('RAMP-CNN Training and Evaluation Metrics')
    fig.tight_layout()
    plt.savefig('training_metrics_history_2h.png')
    print("è®­ç»ƒæŒ‡æ ‡å›¾å·²ä¿å­˜ä¸º training_metrics_history_2h.png")


# ==============================================================================
# --- (4) ä¸»è¿è¡Œå‡½æ•° (test_main - æœ€ç»ˆä¿®å¤é…ç½®) ---
# ==============================================================================

def test_main():
    print("\n=========================================================================")
    print("ğŸš€ å¯åŠ¨ RAMP-CNN 2å°æ—¶ä¼˜åŒ–è®­ç»ƒæµ‹è¯•")
    print("=========================================================================")

    # --- 2å°æ—¶ä¼˜åŒ–é…ç½® ---
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    TEST_EPOCHS = 15
    TEST_BATCH_SIZE = 16
    TEST_MAX_SEQUENCES = 150
    TEST_NUM_WORKERS = 4
    SEQUENCE_LENGTH = 4

    # ğŸ“Œ è¯·æ›¿æ¢ä¸ºæ‚¨çš„çœŸå®æ•°æ®è·¯å¾„
    data_dir = r"H:\python data\Automotive"

    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æµ‹è¯•å‘¨æœŸ (TEST_EPOCHS): {TEST_EPOCHS}")
    print(f"æœ€å¤§åŠ è½½åºåˆ—æ•° (TEST_MAX_SEQUENCES): {TEST_MAX_SEQUENCES}")
    print(f"æµ‹è¯• Batch Size: {TEST_BATCH_SIZE}")
    print(f"åºåˆ—é•¿åº¦ (SEQUENCE_LENGTH): {SEQUENCE_LENGTH} (å‡è®¾ data_processor.py æ”¯æŒ)")

    try:
        test_dataset = RadarDataset(data_dir, sequence_length=SEQUENCE_LENGTH, max_sequences=TEST_MAX_SEQUENCES)
    except Exception as e:
        print(
            f"FATAL ERROR: åˆå§‹åŒ–æ•°æ®é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ '{data_dir}' åŠ data_processor.py ä¸­ sequence_length={SEQUENCE_LENGTH} çš„å…¼å®¹æ€§ã€‚é”™è¯¯: {e}")
        sys.exit(1)

    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=True, num_workers=TEST_NUM_WORKERS,
                             pin_memory=True if torch.cuda.is_available() else False)
    eval_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=TEST_NUM_WORKERS,
                             pin_memory=True if torch.cuda.is_available() else False)

    if len(test_dataset) == 0:
        print("FATAL ERROR: æµ‹è¯•æ•°æ®é›†ä¸ºç©ºã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œåºåˆ—è®¾ç½®ã€‚")
        sys.exit(1)

    print(f"åŠ è½½çš„æµ‹è¯•é›†å¤§å°: {len(test_dataset)} æ‰¹æ¬¡: {len(test_loader)}")
    print("-------------------------------------------------------------------------")

    num_classes = len(label_map)
    model = RAMP_CNN_Lite(num_classes=num_classes, sequence_length=SEQUENCE_LENGTH)

    MAX_LR = 2e-4
    BASE_LR = 1e-5

    # --- æ€§èƒ½æŒ‡æ ‡é…ç½® ---
    # SCORE_THRESHOLD ä¿æŒæä½ï¼Œä½† Peak æå–ä¼šæ§åˆ¶ FP æ•°é‡
    SCORE_THRESHOLD = 1e-6
    PIXEL_THRESHOLD = 3.0

    # --- 3. åˆå§‹åŒ–è¯„ä¼°å™¨ï¼Œä½¿ç”¨ Peak æå–é€»è¾‘ ---
    dummy_processor = RadarDataProcessor(radar_configs)

    metric_calculator = MetricCalculator(
        dummy_processor,
        score_thresh=SCORE_THRESHOLD,
        pixel_range_thresh=PIXEL_THRESHOLD,
        pixel_angle_thresh=PIXEL_THRESHOLD
    )

    trainer = RAMP_CNNTrainer(model, test_loader, eval_loader, device, metric_calculator)

    trainer.optimizer = Adam(model.parameters(), lr=MAX_LR, weight_decay=1e-4)

    # Cyclic LR æ­¥é•¿è®¾ç½®
    step_size = (len(test_dataset) // TEST_BATCH_SIZE) * 2

    trainer.scheduler = CyclicLR(
        trainer.optimizer,
        base_lr=BASE_LR,
        max_lr=MAX_LR,
        step_size_up=step_size,
        cycle_momentum=False
    )
    training_history = {'train_loss': [], 'AP': [], 'AR': []}

    print(f"\nğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•ï¼Œæ€»ç›®æ ‡ {TEST_EPOCHS} ä¸ªå‘¨æœŸã€‚")
    print("=========================================================================")

    for epoch in range(1, TEST_EPOCHS + 1):
        train_loss = trainer.train_epoch(epoch)
        eval_metrics = trainer.evaluate(eval_loader)

        avg_ap = eval_metrics['AP']
        avg_ar = eval_metrics['AR']

        training_history['train_loss'].append(train_loss)
        training_history['AP'].append(avg_ap)
        training_history['AR'].append(avg_ar)

        print(
            f'Epoch {epoch}/{TEST_EPOCHS} | Loss: {train_loss:.6f} | AP: {avg_ap:.2f}%, AR: {avg_ar:.2f}% | Num GT: {eval_metrics["num_gt"]}')
        print(f"å½“å‰å­¦ä¹ ç‡: {trainer.optimizer.param_groups[0]['lr']:.8f}")
        print("-------------------------------------------------------------------------")

    print("\nâœ… 2å°æ—¶ä¼˜åŒ–æµ‹è¯•å®Œæˆ! (è¯·æ ¹æ®å®é™…è¿è¡Œæ—¶é—´è°ƒæ•´ MAX_SEQUENCES/EPOCHS)")
    plot_metrics(training_history, len(training_history['train_loss']))


if __name__ == "__main__":
    test_main()